notebooks use resources


The cleanest way to configure Spark is actually to use the preconfiguration feature available in the **clusters** tab.

youtube: https://youtu.be/3_oV25nZz8I

* reactive 

* directives

* completion

